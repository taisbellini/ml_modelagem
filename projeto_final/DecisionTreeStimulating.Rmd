---
title: "Trabalho Final - Árvores de Decisão"
output: html_notebook
---

## Stimulating

-> primeiro rodar os chunks do Compilado

Colocando os dados em variaveis especificas para o experimento:

```{r}
dataDTStimulating <- data
```

Ajeitando as labels:
```{r}
library(plyr)
dataDTStimulating$Education <- revalue(dataDTStimulating$Education, c("Graduate degree"="Gdg", "Left school"="LS", "Professional certificate/ diploma"="Pct", "Some college or university, no certificate or degree"="Uwodg", "University degree"="Udg"))
dataDTStimulating$Age <- revalue(dataDTStimulating$Age, c("18-24" = "J","25-34" = "JA", "35-44" = "A", "45+" = "MI+"))
dataDTStimulating$NScore <- revalue(dataDTStimulating$NScore, c("VeryLow" = "VL", "Low" = "L", "Average" = "A", "High" = "H", "VeryHigh" = "H"))
dataDTStimulating$AScore <- revalue(dataDTStimulating$AScore, c("VeryLow" = "VL", "Low" = "L", "Average" = "A", "High" = "H", "VeryHigh" = "H"))
dataDTStimulating$CScore <- revalue(dataDTStimulating$CScore, c("VeryLow" = "VL", "Low" = "L", "Average" = "A", "High" = "H", "VeryHigh" = "H"))
dataDTStimulating$OScore <- revalue(dataDTStimulating$OScore, c("VeryLow" = "VL", "Low" = "L", "Average" = "A", "High" = "H", "VeryHigh" = "H"))
dataDTStimulating$EScore <- revalue(dataDTStimulating$EScore, c("VeryLow" = "VL", "Low" = "L", "Average" = "A", "High" = "H", "VeryHigh" = "H"))
dataDTStimulating$Gender <- revalue(dataDTStimulating$Gender, c("Female" = "F", "Male" = "M"))

```

Separar em treino e teste usando o create data partition que garante distribuicoes similares:

```{r}
set.seed(205650)
library(caret)
indexes <- createDataPartition(dataDTStimulating$stimulating_user, p = 0.85, list = FALSE)
trainDTStimulating = dataDTStimulating[indexes, ]
testDTStimulating = dataDTStimulating[-indexes, ]
trainDTStimulating <- subset(trainDTStimulating, select = -c(ID, alcohol_user, ecstasy_user, cannabis_user))
testDTStimulating <- subset(testDTStimulating, select = -c(ID, alcohol_user, ecstasy_user, cannabis_user))

```

Ajustando o modelo da árvore de decisão:
(Obs: rpart usa gini por padrão)
```{r}
#install.packages("rpart")
library(rpart)
model_fit <- rpart(stimulating_user~Age+Gender+Education+NScore+EScore+OScore+AScore+CScore, data = trainDTStimulating, method = "class", control = list(minsplit = 20))

predicted_train <- predict(model_fit, newdata = trainDTStimulating, "class")
predicted_test <- predict(model_fit, newdata = testDTStimulating, "class")

```

Importância de cada Variável:
```{r}
summary(model_fit)
```

Variáveis que foram efetivamente utilizadas pra gerar a árvore:
```{r}
printcp(model_fit)
```

Gerando as Matrizes de Confusão:

```{r}
ctable_train <- confusionMatrix(predicted_train, as.factor(trainDTStimulating$stimulating_user), positive = "1")
ctable_test <- confusionMatrix(predicted_test, as.factor(testDTStimulating$stimulating_user), positive = "1")
ctable_train$table
ctable_test$table

```

Analisando a Acurácia dos Ajustes:

```{r}
print("train")
ctable_train$overall['Accuracy']
print("test")
ctable_test$overall['Accuracy']

```

Analisando as demais medidas do ajuste (sensibilidade, especificidade, etc):

```{r}
ctable_train$byClass
ctable_test$byClass
```

Plot da árvore:

```{r}
#install.packages('rattle')
library(rattle)
library(RColorBrewer)
png('arvore_stimulating.png')
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"))
dev.off()
```

A Sensibilidade (TP rate ou probabilidade de detecção) do ajuste está baixa. Vamos tentar dar mais peso para erros de classificar usuários como não usuários:

```{r}
#install.packages("rpart")
library(rpart)
model_fit_loss <- rpart(stimulating_user~Age+Gender+Education+NScore+EScore+OScore+AScore+CScore, data = trainDTStimulating, method = "class", control = list(minsplit = 20), parms = list(loss=matrix(c(0,1,2,0), byrow=TRUE, nrow=2)))

predicted_train_loss <- predict(model_fit_loss, newdata = trainDTStimulating, "class")
predicted_test_loss <- predict(model_fit_loss, newdata = testDTStimulating, "class")

```

Importância de cada Variável:

```{r}
summary(model_fit_loss)
```

Variáveis que foram efetivamente utilizadas pra gerar a árvore:

```{r}
printcp(model_fit_loss)
```

Gerando as Matrizes de Confusão:

```{r}
ctable_train_loss <- confusionMatrix(predicted_train_loss, as.factor(trainDTStimulating$stimulating_user), positive = "1")
ctable_test_loss <- confusionMatrix(predicted_test_loss, as.factor(testDTStimulating$stimulating_user), positive = "1")
ctable_train_loss$table
ctable_test_loss$table

```

Analisando a Acurácia dos Ajustes:

```{r}
print("train")
ctable_train_loss$overall['Accuracy']
print("test")
ctable_test_loss$overall['Accuracy']

```

Analisando as demais medidas do ajuste (sensibilidade, especificidade, etc):

```{r}
ctable_train_loss$byClass
ctable_test_loss$byClass
```

Plot da árvore:

```{r}
#install.packages('rattle')
library(rattle)
library(RColorBrewer)
png('arvore_stimulating_pesada.png')
fancyRpartPlot(model_fit_loss, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"))
dev.off()
```

Podando a árvore:
("A rule of thumb is to choose the lowest level where rel_error + xstd < xerror." rel_error = erro relativo, x-error = erro de cross-validation, xstd = desvio padrão de cross-validation)

```{r}
optim_table = data.frame(model_fit_loss$cptable)
optim_table = optim_table[optim_table$rel.error + optim_table$xstd < optim_table$xerror, ]
cp_min = optim_table[which.min(optim_table[,"xerror"]),"CP"]
pfit<- prune(model_fit_loss, cp= cp_min)

predicted_train_pruned <- predict(pfit, newdata = trainDTStimulating, "class")
predicted_test_pruned <- predict(pfit, newdata = testDTStimulating, "class")

```

Importância de cada Variável na árvore podada:
```{r}
summary(pfit)
```

Variáveis que foram efetivamente utilizadas pra gerar a árvore podada:

```{r}
printcp(pfit)
```

Gerando as Matrizes de Confusão para a Árvore Podada:

```{r}
ctable_train_pruned <- confusionMatrix(predicted_train_pruned, as.factor(trainDTStimulating$stimulating_user), positive = "1")
ctable_test_pruned <- confusionMatrix(predicted_test_pruned, as.factor(testDTStimulating$stimulating_user), positive = "1")
ctable_train_pruned$table
ctable_test_pruned$table

```

Analisando a Acurácia dos Ajustes da Árvore Podada:

```{r}
print("train")
ctable_train_pruned$overall['Accuracy']
print("test")
ctable_test_pruned$overall['Accuracy']

```

Analisando as demais medidas do ajuste (sensibilidade, especificidade, etc) para a árvore podada:

```{r}
ctable_train_pruned$byClass
ctable_test_pruned$byClass
```

Plot da árvore podada:

```{r}
#install.packages('rattle')
library(rattle)
library(RColorBrewer)
png('arvore_stimulating_podada.png')
fancyRpartPlot(pfit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"))
dev.off()
```
    