---
title: "Trabalho Final - Árvores de Decisão"
output: html_notebook
---

## Stimulating

-> primeiro rodar os chunks do Compilado

Colocando os dados em variaveis especificas para o experimento:

```{r}
dataDTStimulating <- data
```

Separar em treino e teste usando o create data partition que garante distribuicoes similares:

```{r}
set.seed(205650)
library(caret)
indexes <- createDataPartition(dataDTStimulating$stimulating_user, p = 0.85, list = FALSE)
trainDTStimulating = dataDTStimulating[indexes, ]
testDTStimulating = dataDTStimulating[-indexes, ]
trainDTStimulating <- subset(trainDTStimulating, select = -c(ID, alcohol_user, ecstasy_user, cannabis_user, Country, Ethnicity))
testDTStimulating <- subset(testDTStimulating, select = -c(ID, alcohol_user, ecstasy_user, cannabis_user, Country, Ethnicity))

```

Ajustando o modelo da árvore de decisão:
(Obs: rpart usa gini por padrão)
```{r}
#install.packages("rpart")
library(rpart)
model_fit <- rpart(stimulating_user~Age+Gender+Education+NScore+EScore+OScore+AScore+CScore, data = trainDTStimulating, method = "class", control = list(minsplit = 20))

predicted_train <- predict(model_fit, newdata = trainDTStimulating, "class")
predicted_test <- predict(model_fit, newdata = testDTStimulating, "class")

```

Importância de cada Variável:
```{r}
summary(model_fit)
```

Variáveis que foram efetivamente utilizadas pra gerar a árvore:
```{r}
printcp(model_fit)
```

Gerando as Matrizes de Confusão:

```{r}
ctable_train <- confusionMatrix(predicted_train, as.factor(trainDTStimulating$stimulating_user), positive = "1")
ctable_test <- confusionMatrix(predicted_test, as.factor(testDTStimulating$stimulating_user), positive = "1")
ctable_train$table
ctable_test$table

```

Analisando a Acurácia dos Ajustes:

```{r}
print("train")
ctable_train$overall['Accuracy']
print("test")
ctable_test$overall['Accuracy']

```

Analisando as demais medidas do ajuste (sensibilidade, especificidade, etc):

```{r}
ctable_train$byClass
ctable_test$byClass
```

Plot feio (mas melhor de enxergar árvore completa):
```{r}
par(xpd = NA)
plot(model_fit, uniform=TRUE,
   main="Classification Tree")
text(model_fit, use.n=TRUE, all=TRUE, cex=.8)

```

Plot bonito:
```{r}
library(rpart.plot)
rpart.plot(model_fit, yesno = 2, tweak = 1)
```

Plot ainda mais bonito:

```{r}
#install.packages('rattle')
library(rattle)
library(RColorBrewer)
fancyRpartPlot(model_fit, caption = NULL)
```


Podando a árvore:
("A rule of thumb is to choose the lowest level where rel_error + xstd < xerror." rel_error = erro relativo, x-error = erro de cross-validation, xstd = desvio padrão de cross-validation)

```{r}
optim_table = data.frame(model_fit$cptable)
optim_table = optim_table[optim_table$rel.error + optim_table$xstd < optim_table$xerror, ]
cp_min = optim_table[which.min(optim_table[,"xerror"]),"CP"]
pfit<- prune(model_fit, cp= cp_min)

predicted_train_pruned <- predict(pfit, newdata = trainDTStimulating, "class")
predicted_test_pruned <- predict(pfit, newdata = testDTStimulating, "class")

```

Importância de cada Variável na árvore podada:
```{r}
summary(pfit)
```

Variáveis que foram efetivamente utilizadas pra gerar a árvore podada:

```{r}
printcp(pfit)
```

Gerando as Matrizes de Confusão para a Árvore Podada:

```{r}
ctable_train_pruned <- confusionMatrix(predicted_train_pruned, as.factor(trainDTStimulating$stimulating_user), positive = "1")
ctable_test_pruned <- confusionMatrix(predicted_test_pruned, as.factor(testDTStimulating$stimulating_user), positive = "1")
ctable_train_pruned$table
ctable_test_pruned$table

```

Analisando a Acurácia dos Ajustes da Árvore Podada:

```{r}
print("train")
ctable_train_pruned$overall['Accuracy']
print("test")
ctable_test_pruned$overall['Accuracy']

```

Analisando as demais medidas do ajuste (sensibilidade, especificidade, etc) para a árvore podada:

```{r}
ctable_train_pruned$byClass
ctable_test_pruned$byClass
```

Plot feio da árvore podada:
```{r}
par(xpd = NA)
plot(pfit, uniform=TRUE,
   main="Árvore de Decisão Podada para Stimulating")
text(pfit, use.n=TRUE, all=TRUE, cex=.8)

```

Plot bonito da árvore podada:

```{r}
rpart.plot(pfit, yesno = 2, tweak = 1)
```

Plot ainda mais bonito da árvore podada:

```{r}
fancyRpartPlot(pfit, caption = NULL)
```
