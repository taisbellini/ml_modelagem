---
title: "Trabalho Final - Regressao Logistica"
output: html_notebook
---

## Stimulating

-> primeiro rodar os chunks do Compilado

Colocando os dados em variaveis especificas para o experimento:

```{r}
dataLogStimulating <- data
xtabs(~ stimulating_user + CScore, data = dataLogStimulating)
xtabs(~ stimulating_user + NScore, data = dataLogStimulating)
xtabs(~ stimulating_user + OScore, data = dataLogStimulating)
xtabs(~ stimulating_user + AScore, data = dataLogStimulating)
xtabs(~ stimulating_user + EScore, data = dataLogStimulating)
xtabs(~ stimulating_user + Gender, data = dataLogStimulating)
xtabs(~ stimulating_user + Age, data = dataLogStimulating)
xtabs(~ stimulating_user + Education, data = dataLogStimulating)

table(dataLogStimulating$stimulating_user)
```

Separar em treino e teste usando o create data partition que garante distribuicoes similares:

```{r}
set.seed(205650)
indexes <- createDataPartition(dataLogStimulating$stimulating_user, p = 0.85, list = FALSE)
trainLogStimulating = dataLogStimulating[indexes, ]
testLogStimulating = dataLogStimulating[-indexes, ]
```

Rodando o glm full model:
```{r}
trainLogStimulating <- subset(trainLogStimulating, select = -c(ID, alcohol_user, ecstasy_user, cannabis_user))


fullModLogStimulating <- glm(stimulating_user ~ ., data=trainLogStimulating, family = "binomial")
fullModLogStimulating

```

```{r}
predFullStimulating <- ifelse(predict(fullModLogStimulating, newdata = testLogStimulating) >= 0.5, 1, 0)
confusionMatrix(table(predFullStimulating, testLogStimulating$stimulating_user))
```


Ponto de corte em 0.8:
```{r}
predFullStimulating08 <- ifelse(predict(fullModLogStimulating, newdata = testLogStimulating) >= 0.8, 1, 0)
confusionMatrix(table(predFullStimulating08, testLogStimulating$stimulating_user))

```

```{r}
predFullStimulating03 <- ifelse(predict(fullModLogStimulating, newdata = testLogStimulating) >= 0.3, 1, 0)
confusionMatrix(table(predFullStimulating03, testLogStimulating$stimulating_user))

```


Rodando com stepAIC:
```{r}
stepStimulating <- stepAIC(fullModLogStimulating, direction = "backward")
stepStimulating$anova

```

Resumo
```{r}
summary(stepStimulating)
```


```{r}
predStepStimulating <- ifelse(predict(stepStimulating, newdata = testLogStimulating) >= 0.75, 1, 0)
confusionMatrix(table(predStepStimulating, testLogStimulating$stimulating_user))

```


```{r}
library(ggplot2)
## now we can plot the data
predicted.data <- data.frame(
  prob.user=stepStimulating$fitted.values,
  user=trainLogStimulating$stimulating_user)
 
predicted.data <- predicted.data[
  order(predicted.data$prob.user, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)
 
ggplot(data=predicted.data, aes(x=rank, y=prob.user)) +
  geom_point(aes(color=user), alpha=1, shape=4, stroke=2) +
  xlab("Index") +
  ylab("Predicted probability of being a Stimulating drug user")
```

Importancia das variaveis: 
```{r}
variableImportance <- varImp(fullModLogStimulating , scale = FALSE)
variableImportance
```

Calculando o odds ratio:
Quando é < 1 a interpretação fica 

OScoreVeryLow: 0.54 -> Pessoas com esse score baixo tem 46% de chance menor de ser usuario quando comparado as demais classes deste escore.

Ethnicity dar uma olhada na distribuicao para explicar.

OScoreHigh 1.31 -> a chance de ser usuario eh 1.31x maior de ser usuario do que as demais categorias.  

```{r}
stepStimulating
round(exp(coef(stepStimulating)), 2)
```



## Referencias
http://www.sthda.com/english/articles/36-classification-methods-essentials/150-stepwise-logistic-regression-essentials-in-r/
http://www.utstat.toronto.edu/~brunner/oldclass/appliedf11/handouts/2101f11StepwiseLogisticR.pdf
https://machinelearningmastery.com/how-to-estimate-model-accuracy-in-r-using-the-caret-package/