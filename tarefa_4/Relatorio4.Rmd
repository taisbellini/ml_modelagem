---
title: "Tarefa 4 - Classificação"
author: "Tais Bellini"
date: "2/19/2020"
output: pdf_document
---


```{r setup, include=FALSE}
#install.packages("caret")
#install.packages("tidyverse")
#install.packages('rattle')
#install.packages("neuralnet")
library(caret)
library(tidyverse)
library(MASS)
library (e1071)
library(rpart)
library(rattle)
library(RColorBrewer)
library(knitr)
library(neuralnet)
library(scales)
library(ggplot2)

```


# Introdução 

Para este estudo, temos um banco de dados que possui variáveis categóricas e numéricas com informações sobre pacientes com câncer. Algumas variáveis categóricas não estavam definidas como fatores, assim como algumas das numéricas estavam classificadas em categorias. Portanto, se fez um ajuste inicial de forma que variáveis categóricas fossem reconhecidas como fatores e as numéricas como números, utilizando as funções **as.factor()** e **as.numeric()**.

As variáveis categóricas são:

* Paciente em remissão (**remission**): Níveis são 1 e 2, consideramos 1 = "Sim" e 2 = "Não" e recodificamos para 1 e 0, respectivamente;
* Paciente é casado (**Married**): Níveis são 0 e 1, consideramos 0 = "Não" e 1 = "Sim";
* Paciente possui histórico familiar de câncer (**FamilyHx**): Níveis são 0 e 1, consideramos 0= "Não" e 1 = "Sim";
* Paciente é fumante (**SmokingHx**): Níveis são "never", "former", "current";
* Sexo (**Sex**): Níveis são 1 e 2, consideramos 1 = "Homem", 2 = "Mulher";
* Médico que atendeu o paciente (**DID**): Níveis são "A", "B", "C", "D".

As variáveis numéricas são:

* Tamanho do tumor (**tumorsize**): Contínua;
* Percentual de níveis de co2 (**co2**): Contínua;
* Escala de dor (**pain**): Inteiro de 0 a 10; 
* Escala de mobilidade (**mobility**): Inteiro de 0 a 10;
* Número de tumores (**ntumors**): Inteiro de 0 a 9;
* Número de doses de morfina (**nmorphine**): Inteiro;
* Proporção de capacidade ótima do pulmão (**lungcapacity**): Contínua de 0 a 1;
* Idade (**Age**): Contínua em;
* Contagem de glóbulos brancos no sangue (**WBC**): Contínua; 
* Contagem de glóbulos vermelhos no sangue (**RBC**): Contínua; 
* Indicador de inflamação (**IL6**): Contínua.

Ainda, o banco possui informações faltantes que foram retirados através do recurso **na.omit()**.  

```{r, include = FALSE}
# Read and clean data
data <- read.csv2("../tarefa_3/dadosTarefa3.csv")
data <- transform(data, remission = ifelse(remission == "1", 1, 0))
data <- na.omit(data)
data$tumorsize <- as.numeric(data$tumorsize)
data$co2 <- as.numeric(data$co2)
data$lungcapacity <- as.numeric(data$lungcapacity)
data$WBC <- as.numeric(data$WBC)
data$RBC <- as.numeric(data$RBC)
data$IL6 <- as.numeric(data$IL6)
data$Sex <- as.factor(data$Sex)
data$FamilyHx <- as.factor(data$FamilyHx)
data$remission <- as.factor(data$remission)
data$Married <- as.factor(data$Married)
```

Vamos avaliar alguns métodos de classificação para identificar: o médico que atendeu o paciente, se o paciente está em remissão ou não e se o paciente tem ou teve o hábito de fumar. Além disso, vamos buscar determinar se o paciente está em remissão ou não a partir das variáveis *sexo, histórico familiar, estado civil (casado ou não) e médico que atendeu*.

Para todas as análises, a amostra foi dividida nos conjuntos de treino (85%) e teste (15%) através da função **createDatapartition** do pacote **caret** e com semente **205650**.


```{r,include=FALSE}
dataCont <- data[,c("tumorsize", "co2", "lungcapacity", "Age", "WBC", "RBC", "IL6")]
```


# Avaliação da identificação do médico (DID)

Para avaliar se é possível identificar o médico que atendeu o paciente, considerando os algoritmos vistos até a Terefa 3, vamos utilizar a regressão logística ordinal. Para tal, será usado o pacote **MASS** e a função **polr**.

```{r, include=FALSE}
set.seed(205650)
indexes <- createDataPartition(data$DID, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]
```


```{r, include=FALSE}
ord_reg <- polr(DID~., data = train, Hess = TRUE)
summary(ord_reg)

summary_table <- coef(summary(ord_reg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
predtrain <- predict(ord_reg, newdata = train)
predtest <- predict(ord_reg, newdata = test)
predtrain
cm <- confusionMatrix(table(predtrain, train$DID))
cmtest <- confusionMatrix(table(predtest, test$DID))
cm$table
cm$byClass
cmtest$table
cmtest$byClass[,"Sensitivity"]
cm$overall
cmtest$overall

sens_esp <- cbind(percent(cm$byClass[,"Sensitivity"]), percent(cmtest$byClass[,"Sensitivity"]), percent(cm$byClass[,"Specificity"]), percent(cmtest$byClass[,"Specificity"]))
colnames(sens_esp) <- c("Sensibilidade Treino", "Sensibilidade Teste", "Especificidade Treino", "Especificidade Teste")
sens_esp
acc <- cbind(percent(cm$overall['Accuracy']), percent(cmtest$overall['Accuracy']))
colnames(acc) <- c("Treino", "Teste")
```

Na tabela 1, podemos observar a matriz de confusão resultante no conjunto de treino, sendo a linha o valor verdadeiro e a coluna o valor predito pelo modelo. Observa-se nas tabelas 2 e 3 que o resultado não foi satisfatório, sendo a acurácia no conjunto de treino `r percent(cm$overall['Accuracy'])` e no de teste `r percent(cmtest$overall['Accuracy'])`. Com este método e as variáveis disponíveis, não é adequado classificar qual médico atendeu o paciente.


```{r, echo=FALSE}
knitr::kable(cm$table, format = "latex", caption = "Matriz de confusão da Regressão Logísitica ordinal para DID", label = "cm_polr_did")
knitr::kable(acc, format = "latex", caption = "Acurácia da Regressão Logística ordinal para DID")
knitr::kable(sens_esp, format = "latex", caption = "Sensibilidade e Especificidade da Regressão Logística ordinal para DID")
```


Para a Tarefa 4, foi usada a abordagem de rede neural, através da função **neuralnet** do pacote de mesmo nome. Os parâmetros o número de neurônios escondidos (vértices) foi 2 e as variáveis utilizadas foram as numéricas.

```{r, include=FALSE}
# fit neural network
nn=neuralnet(DID~tumorsize + co2 + lungcapacity + Age + WBC + RBC + IL6,data=train, hidden=2, act.fct = "logistic", linear.output = FALSE)
```

```{r, fig.cap="Plot da rede neural para DID", echo=FALSE, out.width="65%", fig.align="center"}
plot(nn, rep = "best")
```

```{r, include=FALSE}
#Treino
Predict=compute(nn,train)
prob <- Predict$net.result
pred <-  max.col(prob, 'first')
pred <- ifelse(pred == 1, "A", ifelse(pred==2, "B", ifelse(pred == 3, "C", "D")))
pred <- factor(pred, levels = c("A", "B", "C", "D"))
cmrn <- confusionMatrix(table(pred, train$DID))

#Teste
Predict=compute(nn,test)
prob <- Predict$net.result
pred <-  max.col(prob, 'first')
pred <- ifelse(pred == 1, "A", ifelse(pred==2, "B", ifelse(pred == 3, "C", "D")))
pred <- factor(pred, levels = c("A", "B", "C", "D"))
cmrntest <- confusionMatrix(table(pred, test$DID))

sens_esprn <- cbind(percent(cmrn$byClass[,"Sensitivity"]), percent(cmrntest$byClass[,"Sensitivity"]), percent(cmrn$byClass[,"Specificity"]), percent(cmrntest$byClass[,"Specificity"]))
colnames(sens_esprn) <- c("Sensibilidade Treino", "Sensibilidade Teste", "Especificidade Treino", "Especificidade Teste")
sens_esprn
accrn <- cbind(percent(cmrn$overall['Accuracy']), percent(cmrntest$overall['Accuracy']))
colnames(accrn) <- c("Treino", "Teste")

```

```{r rn, echo=FALSE}
knitr::kable(cmrn$table, format = "latex", caption = "Matriz de confusão da Rede Neural para DID", label = "cm_polr_did")
knitr::kable(accrn, format = "latex", caption = "Acurácia da Rede Neural para DID")
knitr::kable(sens_esprn, format = "latex", caption = "Sensibilidade e Especificidade da Rede Neural para DID")
```

As tabelas 4, 5 e 6 demonstram que os os resultados com redes neurais também não foram satisfatórios. A acurácia de treino e teste foi `r percent(cmrn$overall['Accuracy'])` e `r percent(cmrntest$overall['Accuracy'])`, respectivamente. Observa-se que a rede neural obteve piores resultados no conjunto de treino do que a regressão logística, mas melhores no conjunto de teste e que a classe B foi melhor predita pela rede neural.

```{r, include=FALSE}
set.seed(205650)
indexes <- createDataPartition(data$DID, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

model_fit <- rpart(DID ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao

cmdt <- confusionMatrix(predicted_train, train$DID)
cmdttest <- confusionMatrix(predicted_test, test$DID)
```

Vamos avaliar mais um método de classificação, a árvore de decisão. Para gerar a árvore de decisão, foi usada a função **rpart**. Novamente, observamos nas tabelas 7, 8 e 9 que o modelo não apresenta bons resultados, sendo a acurácia da predição no conjunto de treino `r percent(cmdt$overall['Accuracy'])` e no de teste `r percent(cmdttest$overall['Accuracy'])`. Neste caso, a acurácia no conjunto de treino é melhor do que no conjunto de teste, ao contrário da rede neural.

```{r dt, echo=FALSE}
sens_espdt <- cbind(percent(cmdt$byClass[,"Sensitivity"]), percent(cmdttest$byClass[,"Sensitivity"]), percent(cmdt$byClass[,"Specificity"]), percent(cmdttest$byClass[,"Specificity"]))
colnames(sens_espdt) <- c("Sensibilidade Treino", "Sensibilidade Teste", "Especificidade Treino", "Especificidade Teste")
sens_espdt
accdt <- cbind(percent(cmdt$overall['Accuracy']), percent(cmdttest$overall['Accuracy']))
colnames(accdt) <- c("Treino", "Teste")
knitr::kable(cmdt$table, format = "latex", caption = "Matriz de confusão da árvore de decisão para DID")

knitr::kable(accdt, format = "latex", caption = "Acurácia da árvore de decisão para DID")

knitr::kable(sens_espdt, format = "latex", caption = "Sensibilidade e Especificidade da árvore de decisão para DID")

```


```{r, fig.cap="árvore gerada para DID", out.width="65%", fig.align="center", echo=FALSE}
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds", "Greens", "Purples"), tweak = 1)
```



# Avaliação da identificação se o paciente está em remissão

Para a identificação se o paciente está em remissão, considerando os métodos vistos até a Tarefa 3 do curso, a regressão logística se mostrou adequada, pois **remission** é uma variável dicotômica e este algoritmo funciona bem para este tipo de classificação. Além disso, é possível utilizar tanto as variáveis categóricas quanto numéricas.

## Resultados Regressão Logística binomial

A função **glm** do pacote **MASS** foi utilizada para estimar o modelo de regressão logística binomial. Após a execução do modelo quase completo (*lungcapacity* foi retirado pois o modelo não convergiu com todas as variáveis), foi aplicada a função **stepAIC**, que faz a seleção de variáveis através do *stepwise* (foi escolhido o método *backard*) tendo como critério o AIC. 

```{r}
set.seed(205650)
indexes <- createDataPartition(data$remission, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

fullMod <- glm(remission ~ DID + pain + Sex + SmokingHx + FamilyHx + Married + nmorphine + ntumors + mobility + tumorsize + co2 + Age + WBC + RBC + IL6, data = train, family = "binomial")
summary(fullMod)
stepMod <- stepAIC(fullMod, direction = "backward")
stepMod$anova
```

O modelo final, após o *stepwise backard*, contém as seguintes variáveis:  **SmokingHx, FamilyHx, mobility, tumorsize e IL6**. As variáveis consideradas significativas (p-valor < 0.05) foram: **SmokingHx, mobility, tumorsize, DID, Sex, Married**.


Os resultados obtidos foram:

Treino: 82,37% de acuracia, 75,71% de sensibilidade e 89,74% de especificidade.
Teste: 83,33% de acuracia, 100% sensibilidade, 66,67% de especificidade.
```{r}
predStepTrain <- ifelse(predict(stepMod, newdata = train) >= 0.5, 1, 0)
cm <- confusionMatrix(table(predStepTrain, train$remission), positive = "1")
cm$byClass

kable(cm$byClass)
```

```{r}
predStepTest <- ifelse(predict(stepMod, newdata = test) >= 0.5, 1, 0)
cm <- confusionMatrix(table(predStepTest, test$remission), positive = "1")
cm
```

Portanto, conclui-se que sim, pode-se identificar se o paciente está em remissão com aproximadamente 80% de acurácia. Apesar de uma acurácia relativamente boa, não considera-se um bom modelo, pois, neste caso, a especificidade tem grande importância (queremos identificar corretamente quem não está em remissão para definir um novo tratamento) e obteve um resultado pouco satisfatório.


Considerando os métodos apresentados para a Tarefa 4, utilizaremos SVM, que também é um bom algoritmo para classificação de variáveis dicotômicas. 
Contudo, ele é adequado para variáveis numéricas, portanto, utilizaremos apenas estas variáveis na análise. 

SVM para as variáveis numéricas:
```{r}
dataSVM <- na.omit(dataCont)
dataSVM <- cbind(remission = data[,"remission"], dataSVM)
head(dataSVM)
summary(dataSVM)

set.seed(205650)
indexes <- createDataPartition(dataSVM$remission, p = 0.85, list = FALSE)
train = dataSVM[indexes, ]
test = dataSVM[-indexes, ]

svmfit = svm(remission ~ ., data = train, kernel ="linear", cost = 10, scale = FALSE )
summary(svmfit)

# indice dos support vectors:
svmfit$index
svmfit$coefs
dataSVM[svmfit$index,]

# betas:
#beta0 = svmfit$rho
#svmfit$coefs
#c(svmfit$coefs)
#betas = c(svmfit$coefs)%*%as.matrix(train[svmfit$index,])
#coefs <- cbind(intercept = beta0, betas)


#formula <- paste(round(coefs, 1), colnames(coefs), sep = "*", collapse = " ")
#formula

# matrix de confus?o:
confusionMatrix(table(predict(svmfit), train$remission), positive="1")
```

SVM ficou com 89,87% de acuracia, 92,50% de sensibilidade e 87,18% de especificidade.

Para visualizar, vamos escolher as duas variáveis consideradas mais importantes pelo modelo: 

```{r}
w <- t(svmfit$coefs) %*% svmfit$SV                 # weight vectors
w
w <- apply(w, 2, function(v){sqrt(sum(v^2))})    # weight
w <- sort(w, decreasing = T)
w

```

```{r}
svmfit2 = svm(remission ~ lungcapacity + Age, data = train, kernel ="linear", cost = 10, scale = FALSE )
head(train)
summary(svmfit2)
dat = data.frame(lungcapacity = train$lungcapacity, Age = train$Age,  remission = as.factor( train$remission ))
dat
# limites de decis?o:
plot(svmfit2, dat, grid = 100, svSymbol = "X", dataSymbol = 19)
```

O SVM apresentou resultados satisfatórios, porém, foram utilizadas apenas a variáveis contínuas. Dessa forma, vamos avaliar o desfecho remissão com Árvore de Decisão:

```{r}
set.seed(205650)
indexes <- createDataPartition(data$remission, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

model_fit <- rpart(remission ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(train$remission), positive = "1")
ctable_test <- confusionMatrix(predicted_test, as.factor(test$remission), positive = "1")
ctable_train$table
ctable_test$table
ctable_train
ctable_test

fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"), tweak = 1)
dev.off()

```

Observamos uma acurácia de 91% no treino e 100% no teste. São resultados muito satisfatórios, porém é importante ressaltar que o banco possui 91 observações, ou seja, apenas 12 observações foram utilizadas para o teste.

# Avaliação da identificação se o paciente é fumante

Regressao logistica ordinal
```{r}
head(data)
ggplot(data, aes(x = SmokingHx, y = lungcapacity, fill = SmokingHx)) +   geom_boxplot(size = .75) +   facet_grid(Sex ~ DID, margins = FALSE) +   theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

```{r}
head(data)
ggplot(data, aes(x = SmokingHx, y = tumorsize, fill = SmokingHx)) +   geom_boxplot(size = .75) +   facet_grid(Sex ~ DID, margins = FALSE) +   theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

```{r}
head(data)
str(data)
set.seed(205650)
indexes <- createDataPartition(data$SmokingHx, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

ord_reg <- polr(SmokingHx~tumorsize+pain+mobility+ntumors+Married+Sex+DID+IL6+co2+lungcapacity+nmorphine, data = train, Hess = TRUE)
summary(ord_reg)

summary_table <- coef(summary(ord_reg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

vars com p-value < 0.05: tumorsize, lungcapacity

```{r}
ord_reg_sg <- polr(SmokingHx~tumorsize+lungcapacity, data = train, Hess = TRUE)
summary(ord_reg_sg)
summary_table <- coef(summary(ord_reg_sg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```
Comparando:
```{r}
predsig<- predict(ord_reg_sg, newdata = train)
pred <- predict(ord_reg, newdata = train)
confusionMatrix(table(predsig, train$SmokingHx))
confusionMatrix(table(pred, train$SmokingHx))
```

```{r}
predtest <- predict(ord_reg, newdata = test)
confusionMatrix(table(predtest, test$SmokingHx))
```


Árvore:

```{r}
set.seed(205650)
indexes <- createDataPartition(data$SmokingHx, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]
model_fit <- rpart(SmokingHx ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(train$SmokingHx))
ctable_test <- confusionMatrix(predicted_test, as.factor(test$SmokingHx))
ctable_train$table
ctable_test$table
ctable_train
ctable_test

fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds", "Greens"), tweak = 1)
dev.off()

```



## Remissao + vars definidas
Utilize um modelo apropriado para analisar a relação entre o desfecho remissão e as variáveis sexo,
histórico familiar, estado civil e DID.

tarefa 3 - Reg logistica
tarefa 4 - tree

```{r}
model_fit <- rpart(remission~Sex+FamilyHx+Married+DID, data = data, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = data, "class")
predicted_test <- predict(model_fit, newdata = data, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(data$remission))
ctable_test <- confusionMatrix(predicted_test, as.factor(data$remission))
ctable_train$table
ctable_test$table
ctable_train
ctable_test

#install.packages('rattle')
library(rattle)
library(RColorBrewer)
png('arvore_cannabis.png')
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"), tweak = 1)
dev.off()

```



https://towardsdatascience.com/do-you-know-how-to-choose-the-right-machine-learning-algorithm-among-7-different-types-295d0b0c7f60

https://medium.com/datadriveninvestor/choosing-the-best-algorithm-for-your-classification-model-7c632c78f38f

http://jmlr.csail.mit.edu/papers/v3/guyon03a.html

https://towardsdatascience.com/implementing-and-interpreting-ordinal-logistic-regression-1ee699274cf5

https://www.datacamp.com/community/tutorials/neural-network-models-r

https://www.theanalysisfactor.com/logistic-regression-models-for-multinomial-and-ordinal-variables/

