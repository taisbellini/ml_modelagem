---
title: "Tarefa 4 - Classificação"
author: "Tais Bellini"
date: "2/20/2020"
output: pdf_document
---


```{r setup, include=FALSE}
#install.packages("caret")
#install.packages("tidyverse")
#install.packages('rattle')
#install.packages("neuralnet")
library(caret)
library(tidyverse)
library(MASS)
library (e1071)
library(rpart)
library(rattle)
library(RColorBrewer)
library(knitr)
library(neuralnet)
library(scales)
library(ggplot2)

```


# Introdução 

Para este estudo, temos um banco de dados que possui variáveis categóricas e numéricas com informações sobre pacientes com câncer. Algumas variáveis categóricas não estavam definidas como fatores, assim como algumas das numéricas estavam classificadas em categorias. Portanto, se fez um ajuste inicial de forma que variáveis categóricas fossem reconhecidas como fatores e as numéricas como números, utilizando as funções **as.factor()** e **as.numeric()**.

As variáveis categóricas são:

* Paciente em remissão (**remission**): Níveis são 1 e 2, consideramos 1 = "Sim" e 2 = "Não" e recodificamos para 1 e 0, respectivamente;
* Paciente é casado (**Married**): Níveis são 0 e 1, consideramos 0 = "Não" e 1 = "Sim";
* Paciente possui histórico familiar de câncer (**FamilyHx**): Níveis são 0 e 1, consideramos 0= "Não" e 1 = "Sim";
* Paciente é fumante (**SmokingHx**): Níveis são "never", "former", "current";
* Sexo (**Sex**): Níveis são 1 e 2, consideramos 1 = "Homem", 2 = "Mulher";
* Médico que atendeu o paciente (**DID**): Níveis são "A", "B", "C", "D".

As variáveis numéricas são:

* Tamanho do tumor (**tumorsize**): Contínua;
* Percentual de níveis de co2 (**co2**): Contínua;
* Escala de dor (**pain**): Inteiro de 0 a 10; 
* Escala de mobilidade (**mobility**): Inteiro de 0 a 10;
* Número de tumores (**ntumors**): Inteiro de 0 a 9;
* Número de doses de morfina (**nmorphine**): Inteiro;
* Proporção de capacidade ótima do pulmão (**lungcapacity**): Contínua de 0 a 1;
* Idade (**Age**): Contínua em;
* Contagem de glóbulos brancos no sangue (**WBC**): Contínua; 
* Contagem de glóbulos vermelhos no sangue (**RBC**): Contínua; 
* Indicador de inflamação (**IL6**): Contínua.

Ainda, o banco possui informações faltantes que foram retirados através do recurso **na.omit()**.  

```{r, include = FALSE}
# Read and clean data
data <- read.csv2("../tarefa_3/dadosTarefa3.csv")
data <- transform(data, remission = ifelse(remission == "1", 1, 0))
data <- na.omit(data)
data$tumorsize <- as.numeric(data$tumorsize)
data$co2 <- as.numeric(data$co2)
data$lungcapacity <- as.numeric(data$lungcapacity)
data$WBC <- as.numeric(data$WBC)
data$RBC <- as.numeric(data$RBC)
data$IL6 <- as.numeric(data$IL6)
data$Sex <- as.factor(data$Sex)
data$FamilyHx <- as.factor(data$FamilyHx)
data$remission <- as.factor(data$remission)
data$Married <- as.factor(data$Married)
```

Vamos avaliar alguns métodos de classificação para identificar: o médico que atendeu o paciente, se o paciente está em remissão ou não e se o paciente tem ou teve o hábito de fumar. Além disso, vamos buscar determinar se o paciente está em remissão ou não a partir das variáveis *sexo, histórico familiar, estado civil (casado ou não) e médico que atendeu*.

Para todas as análises, a amostra foi dividida nos conjuntos de treino (85%) e teste (15%) através da função **createDatapartition** do pacote **caret** e com semente **205650**.


```{r,include=FALSE}
dataCont <- data[,c("tumorsize", "co2", "lungcapacity", "Age", "WBC", "RBC", "IL6")]
```


# Avaliação da identificação do médico (DID)

Para avaliar se é possível identificar o médico que atendeu o paciente, considerando os algoritmos vistos até a Terefa 3, vamos utilizar a regressão logística ordinal. Para tal, será usado o pacote **MASS** e a função **polr**.

```{r, include=FALSE}
set.seed(205650)
indexes <- createDataPartition(data$DID, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]
```


```{r, include=FALSE}
ord_reg <- polr(DID~., data = train, Hess = TRUE)
summary(ord_reg)

summary_table <- coef(summary(ord_reg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
predtrain <- predict(ord_reg, newdata = train)
predtest <- predict(ord_reg, newdata = test)
predtrain
cm <- confusionMatrix(table(predtrain, train$DID))
cmtest <- confusionMatrix(table(predtest, test$DID))

sens_esp <- cbind(percent(cm$byClass[,"Sensitivity"]), percent(cmtest$byClass[,"Sensitivity"]), percent(cm$byClass[,"Specificity"]), percent(cmtest$byClass[,"Specificity"]))
colnames(sens_esp) <- c("Sensibilidade Treino", "Sensibilidade Teste", "Especificidade Treino", "Especificidade Teste")
sens_esp
acc <- cbind(percent(cm$overall['Accuracy']), percent(cmtest$overall['Accuracy']))
```

Na tabela 1, podemos observar a matriz de confusão resultante no conjunto de treino, sendo a linha o valor verdadeiro e a coluna o valor predito pelo modelo. Observa-se na tabela 2 que o resultado não foi satisfatório, sendo a acurácia no conjunto de treino `r percent(cm$overall['Accuracy'])` e no de teste `r percent(cmtest$overall['Accuracy'])`. Com este método e as variáveis disponíveis, não é adequado classificar qual médico atendeu o paciente.

Para a Tarefa 4, foi usada a abordagem de rede neural, através da função **neuralnet** do pacote de mesmo nome. Os parâmetros o número de neurônios escondidos (vértices) foi 2 e as variáveis utilizadas foram as numéricas.

```{r, include=FALSE}
# fit neural network
nn=neuralnet(DID~tumorsize + co2 + lungcapacity + Age + WBC + RBC + IL6,data=train, hidden=2, act.fct = "logistic", linear.output = FALSE)
```

```{r, fig.cap="Plot da rede neural para DID", echo=FALSE, out.width="65%", fig.align="center"}
plot(nn, rep = "best")
```

```{r, include=FALSE}
#Treino
Predict=compute(nn,train)
prob <- Predict$net.result
pred <-  max.col(prob, 'first')
pred <- ifelse(pred == 1, "A", ifelse(pred==2, "B", ifelse(pred == 3, "C", "D")))
pred <- factor(pred, levels = c("A", "B", "C", "D"))
cmrn <- confusionMatrix(table(pred, train$DID))

#Teste
Predict=compute(nn,test)
prob <- Predict$net.result
pred <-  max.col(prob, 'first')
pred <- ifelse(pred == 1, "A", ifelse(pred==2, "B", ifelse(pred == 3, "C", "D")))
pred <- factor(pred, levels = c("A", "B", "C", "D"))
cmrntest <- confusionMatrix(table(pred, test$DID))

```


A tabela 2 demonstrm que os os resultados com redes neurais também não foram satisfatórios. A acurácia de treino e teste foi `r percent(cmrn$overall['Accuracy'])` e `r percent(cmrntest$overall['Accuracy'])`, respectivamente. Observa-se que a rede neural obteve piores resultados no conjunto de treino do que a regressão logística, mas melhores no conjunto de teste e que a classe B foi melhor predita pela rede neural.

```{r, include=FALSE}
set.seed(205650)
indexes <- createDataPartition(data$DID, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

model_fit <- rpart(DID ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao

cmdt <- confusionMatrix(predicted_train, train$DID)
cmdttest <- confusionMatrix(predicted_test, test$DID)
```

Vamos avaliar mais um método de classificação, a árvore de decisão. Para gerar a árvore de decisão, foi usada a função **rpart**. Novamente, observamos na tabela 2 que o modelo não apresenta bons resultados, sendo a acurácia da predição no conjunto de treino `r percent(cmdt$overall['Accuracy'])` e no de teste `r percent(cmdttest$overall['Accuracy'])`. Neste caso, a acurácia no conjunto de treino é melhor do que no conjunto de teste, ao contrário da rede neural.


```{r, echo=FALSE}
accdid <- data.frame("Acurácia Treino" = c(percent(cm$overall['Accuracy']),
                                           percent(cmrn$overall['Accuracy']),
                                           percent(cmdt$overall['Accuracy'])),
                     "Acurácia Teste" = c(percent(cmtest$overall['Accuracy']),
                                          percent(cmrntest$overall['Accuracy']),
                                          percent(cmdttest$overall['Accuracy'])), 
                     row.names= c("Regressão Logística Ordinal", "Rede Neural", "Árvore de decisão"))
                                           
knitr::kable(cm$table, format = "latex", caption = "Matriz de confusão para DID no conjunto treino")
knitr::kable(accdid, format = "latex", caption = "Acurácia para DID")
```


```{r, fig.cap="árvore gerada para DID", out.width="65%", fig.align="center", echo=FALSE}
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds", "Greens", "Purples"), tweak = 1)
```



# Avaliação da identificação se o paciente está em remissão

Para a identificação se o paciente está em remissão, considerando os métodos vistos até a Tarefa 3 do curso, a regressão logística se mostrou adequada, pois **remission** é uma variável dicotômica e este algoritmo funciona bem para este tipo de classificação. Além disso, é possível utilizar tanto as variáveis categóricas quanto numéricas.


A função **glm** do pacote **MASS** foi utilizada para estimar o modelo de regressão logística binomial. Após a execução do modelo quase completo (*lungcapacity* foi retirado pois o modelo não convergiu com todas as variáveis), foi aplicada a função **stepAIC**, que faz a seleção de variáveis através do *stepwise* (foi escolhido o método *backard*) tendo como critério o AIC. 

```{r, include=FALSE}
set.seed(205650)
indexes <- createDataPartition(data$remission, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

fullMod <- glm(remission ~ DID + pain + Sex + SmokingHx + FamilyHx + Married + nmorphine + ntumors + mobility + tumorsize + co2 + Age + WBC + RBC + IL6, data = train, family = "binomial")
summary(fullMod)
stepMod <- stepAIC(fullMod, direction = "backward")
stepMod$anova
summary(stepMod)
```

O modelo final, após o *stepwise backard*, contém as seguintes variáveis:  **SmokingHx, FamilyHx, mobility, tumorsize e IL6**. As variáveis consideradas significativas (p-valor < 0.01) foram: **SmokingHx, mobility, tumorsize**.


```{r, include = FALSE}
predStepTrain <- ifelse(predict(stepMod, newdata = train) >= 0.5, 1, 0)
cmrem <- confusionMatrix(table(predStepTrain, train$remission), positive = "1")
predStepTest <- ifelse(predict(stepMod, newdata = test) >= 0.5, 1, 0)
cmremtest <- confusionMatrix(table(predStepTest, test$remission), positive = "1")

```


Os resultados obtidos podem ser observados na tabela 3. Observa-se que a acurácia foi de `r percent(cmrem$overall['Accuracy'])` e `r percent(cmremtest$overall['Accuracy'])` para treino e teste, respectivamente. 

Portanto, conclui-se que sim, pode-se identificar se o paciente está em remissão com aproximadamente 80% de acurácia. Apesar de uma acurácia relativamente boa, não considera-se um bom modelo, pois, neste caso, a especificidade tem grande importância (queremos identificar corretamente quem não está em remissão para definir um novo tratamento) e obteve um resultado pouco satisfatório de `r percent(cmrem$byClass['Specificity'])`.


Considerando os métodos apresentados para a Tarefa 4, utilizaremos SVM, que também é um bom algoritmo para classificação de variáveis dicotômicas. Contudo, ele é adequado para variáveis numéricas, portanto, utilizaremos apenas estas variáveis na análise. 


```{r, include=FALSE}
dataSVM <- na.omit(dataCont)
dataSVM <- cbind(remission = data[,"remission"], dataSVM)
head(dataSVM)
summary(dataSVM)

set.seed(205650)
indexes <- createDataPartition(dataSVM$remission, p = 0.85, list = FALSE)
train = dataSVM[indexes, ]
test = dataSVM[-indexes, ]

svmfit = svm(remission ~ ., data = train, kernel ="linear", cost = 10, scale = FALSE )
summary(svmfit)

# indice dos support vectors:
svmfit$index
svmfit$coefs
dataSVM[svmfit$index,]

# betas:
#beta0 = svmfit$rho
#svmfit$coefs
#c(svmfit$coefs)
#betas = c(svmfit$coefs)%*%as.matrix(train[svmfit$index,])
#coefs <- cbind(intercept = beta0, betas)


#formula <- paste(round(coefs, 1), colnames(coefs), sep = "*", collapse = " ")
#formula

# matrix de confus?o:

cmsvm <- confusionMatrix(table(predict(svmfit, train), train$remission), positive="1")
cmsvmtest <- confusionMatrix(table(predict(svmfit, test), test$remission), positive="1")

```


Observamos pelos resultados da tabela 3 que SVM teve uma acurácia de `r percent(cmsvm$overall['Accuracy'])` e `r percent(cmsvmtest$overall['Accuracy'])` em treino e teste, respectivamente. Além disso, a especificidade foi `r percent(cmsvm$overall['Accuracy'])` e `r percent(cmsvmtest$overall['Accuracy'])`.

Para visualizar, vamos escolher as duas variáveis consideradas mais importantes pelo modelo: **lungcapacity** e **Age**. A figura 3 ilustra os *support vectors* com um **X**.

```{r, include=FALSE}
w <- t(svmfit$coefs) %*% svmfit$SV                 # weight vectors
w
w <- apply(w, 2, function(v){sqrt(sum(v^2))})    # weight
w <- sort(w, decreasing = T)
w

```

```{r, include=FALSE}
svmfit2 = svm(remission ~ lungcapacity + Age, data = train, kernel ="linear", cost = 10, scale = FALSE )
head(train)
summary(svmfit2)
dat = data.frame(lungcapacity = train$lungcapacity, Age = train$Age,  remission = as.factor( train$remission ))
dat
# limites de decis?o:

```

```{r, fig.cap="Plot do SVM para remissão", echo=FALSE, out.width="65%", fig.align="center"}
plot(svmfit2, dat, grid = 100, svSymbol = "X", dataSymbol = 19)
```

O SVM apresentou resultados bem satisfatórios, porém, foram utilizadas apenas a variáveis contínuas. 

```{r, include = FALSE}
set.seed(205650)
indexes <- createDataPartition(data$remission, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

model_fit <- rpart(remission ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(train$remission), positive = "1")
ctable_test <- confusionMatrix(predicted_test, as.factor(test$remission), positive = "1")
ctable_train$table
ctable_test$table
ctable_train
ctable_test

```


```{r, echo=FALSE}
accdid <- data.frame("Acurácia Treino" = c(percent(cmrem$overall['Accuracy']),
                                           percent(cmsvm$overall['Accuracy']),
                                           percent(ctable_train$overall['Accuracy'])),
                     "Acurácia Teste" = c(percent(cmrem$overall['Accuracy']),
                                          percent(cmsvmtest$overall['Accuracy']),
                                          percent(ctable_test$overall['Accuracy'])), 
                     row.names= c("Regressão Logística binomial", "SVM", "Árvore de decisão"))
                                           
knitr::kable(accdid, format = "latex", caption = "Acurácia para remissão")
```


```{r, fig.cap="Plot da árvore de decisão para remissão", echo=FALSE, out.width="65%", fig.align="center"}
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"), tweak = 1)
```


Por fim, avaliando o desfecho remissão com Árvore de Decisão,  observamos uma acurácia de `r percent(ctable_train$overall['Accuracy'])` (treino) e `r percent(ctable_test$overall['Accuracy'])` (teste), como apresentado na tabela 3. A especificidade foi de `r percent(ctable_train$byClass['Specificity'])` (treino) e `r percent(ctable_test$byClass['Specificity'])` (teste). São resultados muito satisfatórios, porém é importante ressaltar que o banco possui 91 observações, ou seja, apenas 12 observações foram utilizadas para o teste.


# Avaliação da identificação se o paciente é fumante

Para a classificação do paciente de acordo com o hábito de fumar, utilizamos regressão logística ordinal e árvore de decisão, assim como para a identificação do médico que atendeu o paciente.


```{r, include = FALSE}
head(data)
str(data)
set.seed(205650)
indexes <- createDataPartition(data$SmokingHx, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

ord_reg <- polr(SmokingHx~tumorsize+pain+mobility+ntumors+Married+Sex+DID+IL6+co2+lungcapacity+nmorphine, data = train, Hess = TRUE)
summary(ord_reg)

summary_table <- coef(summary(ord_reg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

```{r, include=FALSE}
pred <- predict(ord_reg, newdata = train)
cmsmoke <- confusionMatrix(table(pred, train$SmokingHx))
predtest <- predict(ord_reg, newdata = test)
cmtestsmoke <- confusionMatrix(table(predtest, test$SmokingHx))
```


Observa-se na tabela 4 que a acurácia do modelo foi alta, `r percent(cmsmoke$overall["Accuracy"])`. Ainda, tivemos bons resultados para especificidade e sensibilidade, como demonstrado nas tabelas 5, 6, 7 e 8.


```{r, include = FALSE}
set.seed(205650)
indexes <- createDataPartition(data$SmokingHx, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]
model_fit <- rpart(SmokingHx ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_trainsmoke <- confusionMatrix(predicted_train, as.factor(train$SmokingHx))
ctable_testsmoke <- confusionMatrix(predicted_test, as.factor(test$SmokingHx))

```


```{r fig.cap="Plot da árvore de decisão para hábito de fumar", echo=FALSE, out.width="65%", fig.align="center"}
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds", "Greens"), tweak = 1)
```


```{r, echo=FALSE}
accdid <- data.frame("Acurácia Treino" = c(percent(cmsmoke$overall['Accuracy']),
                                           percent(ctable_trainsmoke$overall['Accuracy'])),
                     "Acurácia Teste" = c(percent(cmtestsmoke$overall['Accuracy']),
                                          percent(ctable_testsmoke$overall['Accuracy'])),
                     row.names= c("Regressão Logística ordinal", "Árvore de decisão"))
                                           
knitr::kable(accdid, format = "latex", caption = "Acurácia para hábito de fumar")
knitr::kable(percent(cmsmoke$byClass[,"Specificity"]), format = "latex", caption = "Especificidade para hábito de fumar conjunto de treino", col.names = c("Especificidade"))
knitr::kable(percent(cmsmoke$byClass[,"Sensitivity"]), format = "latex", caption = "Sensibilidade para hábito de fumar conjunto de treino", col.names = c("Sensibilidade"))
knitr::kable(percent(cmtestsmoke$byClass[,"Specificity"]), format = "latex", caption = "Especificidade para hábito de fumar conjunto de teste", col.names = c("Especificidade"))
knitr::kable(percent(cmtestsmoke$byClass[,"Sensitivity"]), format = "latex", caption = "Sensibilidade para hábito de fumar conjunto de teste", col.names = c("Sensibilidade"))

```

Avaliando a aplicação da árvore de decisão para classificar os pacientes pelo hábito de fumar, também obtivemos ótimos resultados, como visto na tabela 4.

Utilizamos regressão logística e árvore de decisão, entre outros, para buscar classificar as três variáveis até agora: médico que atendeu o paciente, se o paciente está em remissão e se o paciente é fumante. Para a primeira variável, os resultados foram muito insatisfatórios nas métricas de interesse (acurácia e especificidade) independente do método. Por outro lado, estes mesmos métodos apresentaram bons resultados para as outras duas variáveis, o que nos leva a avaliar que as informações deste banco de dados não são relevantes para determinar o médico que atendeu o paciente. 

# Relação entre remissão e variáveis sexo, histórico, estado civil e DID

Para avaliar a relação entre as variáveis sexo, histórico familiar, estado civil e DID com remissão vamos utilizar uma regressão logística binomial, avaliando o *odds ratio* e uma árvore de decisão, avaliando a importância das variáveis e as escolhidas pelo modelo. 


```{r, include = FALSE}
fullMod <- glm(remission~Sex+FamilyHx+Married+DID, data = data, family = "binomial")
summary(fullMod)

stepMod <- stepAIC(fullMod, direction = "backward")

oddsRatio <- round(exp(coef(stepMod)),2)
oddsRatio
```

Aplicando a regressão logística com **remissão** como variável dependente e **Sex, FamilyHx, Married, DID**, observamos que as variáveis **Sex** e **DID** são significativas (p-valor <0.01). O modelo final utilizando o método *stepwise backward* para seleção de variáveis utiliza apenas estas duas variáveis. A tabela 9 demonstra que ser do sexo feminino reduz em 69% a chance de se estar em remissão em oposição a ser do sexo masculino. Similarmente, ser atendido pelo médico de *id* **D** reduz em 81% esta chance, quando comparado com ser atendido pelo médico de *id* **A**.


```{r include=FALSE}
model_fit <- rpart(remission~Sex+FamilyHx+Married+DID, data = data, method = "class", control = list(minsplit = 20))

predicted <- predict(model_fit, newdata = data, "class")

summary(model_fit)

# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted, as.factor(data$remission))

```

```{r, echo = FALSE}
knitr::kable(oddsRatio, format = "latex", caption = "Odds ratio da regressão logística", col.names = c("Odds Ratio"))
knitr::kable(model_fit$variable.importance, format = "latex", caption = "Importância das variáveis árvore de decisão", col.names = c("Importância das variáveis"))
```

Similarmente à regressão logística, observa-se na tabela 10 que **DID** é a variável com mais importância quando utilizamos árvore de decisão, seguida de **Sex**. Poedmos ver pela figura 6 que foram estas variáveis as escolhidas para a construção da árvore.

Assim, através de dois métodos, podemos sugerir que Gênero e a escolha do médico podem influenciar no desfecho da remissão de câncer.

```{r fig.cap="Plot da árvore de decisão para remissão", echo=FALSE, out.width="65%", fig.align="center"}
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"), tweak = 1)
```


# Referências

https://towardsdatascience.com/do-you-know-how-to-choose-the-right-machine-learning-algorithm-among-7-different-types-295d0b0c7f60

https://medium.com/datadriveninvestor/choosing-the-best-algorithm-for-your-classification-model-7c632c78f38f

http://jmlr.csail.mit.edu/papers/v3/guyon03a.html

https://towardsdatascience.com/implementing-and-interpreting-ordinal-logistic-regression-1ee699274cf5

https://www.datacamp.com/community/tutorials/neural-network-models-r

https://www.theanalysisfactor.com/logistic-regression-models-for-multinomial-and-ordinal-variables/

