---
title: "Tarefa 4 - Classificação"
output: word_document
---


```{r, include=FALSE}
#install.packages("caret")
#install.packages("tidyverse")
#install.packages('rattle')
#install.packages("neuralnet")
library(caret)
library(tidyverse)
library(MASS)
library (e1071)
library(rpart)
library(rattle)
library(RColorBrewer)
library(knitr)
library(neuralnet)

```


# Introdução 

Para este estudo, temos um banco de dados que possui variáveis categóricas e numéricas com informações sobre pacientes com câncer. Algumas variáveis categóricas não estavam definidas como fatores, assim como algumas das numéricas estavam classificadas em categorias. Portanto, se fez um ajuste inicial de forma que variáveis categóricas fossem reconhecidas como fatores e as numéricas como números, utilizando as funções **as.factor()** e **as.numeric()**.

As variáveis categóricas são:
* Paciente em remissão (**remission**): Níveis são 1 e 2, consideramos 1 = "Sim" e 2 = "Não" e recodificamos para 1 e 0, respectivamente;
* Paciente é casado (**Married**): Níveis são 0 e 1, consideramos 0 = "Não" e 1 = "Sim";
* Paciente possui histórico familiar de câncer (**FamilyHx**): Níveis são 0 e 1, consideramos 0= "Não" e 1 = "Sim";
* Paciente é fumante (**SmokingHx**): Níveis são "never", "former", "current";
* Sexo (**Sex**): Níveis são 1 e 2, consideramos 1 = "Homem", 2 = "Mulher";
* Médico que atendeu o paciente(**DID**): Níveis são "A", "B", "C", "D".

As variáveis numéricas são: 
* Tamanho do tumor (**tumorsize**): Contínua;
* Percentual de níveis de co2 (**co2**): Contínua;
* Escala de dor (**pain**): Inteiro de 0 a 10; 
* Escala de mobilidade (**mobility**): Inteiro de 0 a 10;
* Número de tumores (**ntumors**): Inteiro de 0 a 9;
* Número de doses de morfina (**nmorphine**): Inteiro;
* Proporção de capacidade ótima do pulmão (**lungcapacity**): Contínua de 0 a 1;
* Idade (**Age**): Contínua em;
* Contagem de glóbulos brancos no sangue (**WBC**): Contínua; 
* Contagem de glóbulos vermelhos no sangue (**RBC**): Contínua; 
* Indicador de inflamação (**IL6**): Contínua.

Ainda, o banco possui informações faltantes que foram retirados através do recurso **na.omit()**.  

```{r, include = FALSE}
# Read and clean data
data <- read.csv2("../tarefa_3/dadosTarefa3.csv")
data <- transform(data, remission = ifelse(remission == "1", 1, 0))
data <- na.omit(data)
data$tumorsize <- as.numeric(data$tumorsize)
data$co2 <- as.numeric(data$co2)
data$lungcapacity <- as.numeric(data$lungcapacity)
data$WBC <- as.numeric(data$WBC)
data$RBC <- as.numeric(data$RBC)
data$IL6 <- as.numeric(data$IL6)
data$Sex <- as.factor(data$Sex)
data$FamilyHx <- as.factor(data$FamilyHx)
data$remission <- as.factor(data$remission)
data$Married <- as.factor(data$Married)
```

Vamos avaliar alguns métodos de classificação para identificar o médico que atendeu o paciente, se o paciente está em remissão ou não e se o paciente tem ou teve o hábito de fumar. Além disso, vamos buscar determinar se o paciente está em remissão ou não a partir das variáveis sexo, histórico familiar, estado civil (casado ou não) e médico que atendeu.

Para todas as análises, a amostra foi dividida nos conjuntos de treino e teste através da função **createDatapartition** do pacote **caret** e com semente **205650**.


```{r}
dataCont <- data[,c("tumorsize", "co2", "lungcapacity", "Age", "WBC", "RBC", "IL6")]
```


# Avaliação da identificação do médico (DID)

Para avaliar se é possível identificar o médico que atendeu o paciente, considerando os algoritmos vistos até a Terefa 3, vamos utilizar a regressão logística ordinal. Para tal, será usado o pacote **MASS** e a função **polr**. Separamos o dataset em treino (85%) e teste (15%).

```{r}
set.seed(205650)
indexes <- createDataPartition(data$DID, p = 0.90, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]
```


```{r}
head(data)
str(data)
ord_reg <- polr(DID~., data = train, Hess = TRUE)
summary(ord_reg)

summary_table <- coef(summary(ord_reg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

Resultados: 

```{r}
predtrain <- predict(ord_reg, newdata = train)
predtest <- predict(ord_reg, newdata = test)
predtrain
cm <- confusionMatrix(table(predtrain, train$DID))
cmtest <- confusionMatrix(table(predtest, test$DID))
cm$table
cm$byClass
cmtest$table
cmtest$byClass
cm$overall
cmtest$overall
```


A acurácia e sensibilidade obtiveram valores muito baixos, sendo a maioria menos de 50%, como observado na Tabela 1. Com este método e as variáveis disponíveis, não é adequado classificar qual médico atendeu o paciente.

para a tarefa 4, foi usada a abordagem de rede neural, através da função **neuralnet** do pacote de mesmo nome. Os parâmetros o número de neurônios escondidos (vértices) foi 2.

```{r}
# fit neural network
nn=neuralnet(DID~tumorsize + co2 + lungcapacity + Age + WBC + RBC + IL6,data=train, hidden=2, act.fct = "logistic",
                linear.output = FALSE)
nnplot <- plot(nn)
```

Treino:
```{r}
Predict=compute(nn,train)
prob <- Predict$net.result
pred <-  max.col(prob, 'first')
pred <- ifelse(pred == 1, "A", ifelse(pred==2, "B", ifelse(pred == 3, "C", "D")))
pred <- factor(pred, levels = c("A", "B", "C", "D"))
confusionMatrix(table(pred, train$DID))
```

Teste:
```{r}
Predict=compute(nn,test)
prob <- Predict$net.result
pred <-  max.col(prob, 'first')
pred <- ifelse(pred == 1, "A", ifelse(pred==2, "B", ifelse(pred == 3, "C", "D")))
pred <- factor(pred, levels = c("A", "B", "C", "D"))
confusionMatrix(table(pred, test$DID))
```

Os resultados com redes neurais também não foram satisfatórios.

Vamos fazer uma tentativa com árvore de decisão:

```{r}
set.seed(205650)
indexes <- createDataPartition(data$DID, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

model_fit <- rpart(DID ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, train$DID)
ctable_test <- confusionMatrix(predicted_test, test$DID)
ctable_train$table
ctable_test$table
ctable_train
ctable_test

fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds", "Greens", "Purples"), tweak = 1)
dev.off()
```

Mesmo com árvore de decisão, não foi possível obter resultados satisfatórios. 


# Avaliação da identificação se o paciente está em remissão

Para a identificação se o paciente está em remissão, considerando os métodos vistos até a Tarefa 3 do curso, a regressão logística se mostrou adequada, pois **remission** é uma variável dicotômica e este algoritmo funciona bem para este tipo de classificação. Além disso, é possível utilizar tanto as variáveis categóricas quanto numéricas.

## Resultados Regressão Logística binomial

A função **glm** do pacote **MASS** foi utilizada para estimar o modelo de regressão logística binomial. Após a execução do modelo quase completo (*lungcapacity* foi retirado pois o modelo não convergiu com todas as variáveis), foi aplicada a função **stepAIC**, que faz a seleção de variáveis através do *stepwise* (foi escolhido o método *backard*) tendo como critério o AIC. 

```{r}
set.seed(205650)
indexes <- createDataPartition(data$remission, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

fullMod <- glm(remission ~ DID + pain + Sex + SmokingHx + FamilyHx + Married + nmorphine + ntumors + mobility + tumorsize + co2 + Age + WBC + RBC + IL6, data = train, family = "binomial")
summary(fullMod)
stepMod <- stepAIC(fullMod, direction = "backward")
stepMod$anova
```

O modelo final, após o *stepwise backard*, contém as seguintes variáveis:  **SmokingHx, FamilyHx, mobility, tumorsize e IL6**. As variáveis consideradas significativas (p-valor < 0.05) foram: **SmokingHx, mobility, tumorsize, DID, Sex, Married**.


Os resultados obtidos foram:

Treino: 82,37% de acuracia, 75,71% de sensibilidade e 89,74% de especificidade.
Teste: 83,33% de acuracia, 100% sensibilidade, 66,67% de especificidade.
```{r}
predStepTrain <- ifelse(predict(stepMod, newdata = train) >= 0.5, 1, 0)
cm <- confusionMatrix(table(predStepTrain, train$remission), positive = "1")
cm$byClass

kable(cm$byClass)
```

```{r}
predStepTest <- ifelse(predict(stepMod, newdata = test) >= 0.5, 1, 0)
cm <- confusionMatrix(table(predStepTest, test$remission), positive = "1")
cm
```

Portanto, conclui-se que sim, pode-se identificar se o paciente está em remissão com aproximadamente 80% de acurácia. Apesar de uma acurácia relativamente boa, não considera-se um bom modelo, pois, neste caso, a especificidade tem grande importância (queremos identificar corretamente quem não está em remissão para definir um novo tratamento) e obteve um resultado pouco satisfatório.


Considerando os métodos apresentados para a Tarefa 4, utilizaremos SVM, que também é um bom algoritmo para classificação de variáveis dicotômicas. 
Contudo, ele é adequado para variáveis numéricas, portanto, utilizaremos apenas estas variáveis na análise. 

SVM para as variáveis numéricas:
```{r}
dataSVM <- na.omit(dataCont)
dataSVM <- cbind(remission = data[,"remission"], dataSVM)
head(dataSVM)
summary(dataSVM)

set.seed(205650)
indexes <- createDataPartition(dataSVM$remission, p = 0.85, list = FALSE)
train = dataSVM[indexes, ]
test = dataSVM[-indexes, ]

svmfit = svm(remission ~ ., data = train, kernel ="linear", cost = 10, scale = FALSE )
summary(svmfit)

# indice dos support vectors:
svmfit$index
svmfit$coefs
dataSVM[svmfit$index,]

# betas:
#beta0 = svmfit$rho
#svmfit$coefs
#c(svmfit$coefs)
#betas = c(svmfit$coefs)%*%as.matrix(train[svmfit$index,])
#coefs <- cbind(intercept = beta0, betas)


#formula <- paste(round(coefs, 1), colnames(coefs), sep = "*", collapse = " ")
#formula

# matrix de confus?o:
confusionMatrix(table(predict(svmfit), train$remission), positive="1")
```

SVM ficou com 89,87% de acuracia, 92,50% de sensibilidade e 87,18% de especificidade.

Para visualizar, vamos escolher as duas variáveis consideradas mais importantes pelo modelo: 

```{r}
w <- t(svmfit$coefs) %*% svmfit$SV                 # weight vectors
w
w <- apply(w, 2, function(v){sqrt(sum(v^2))})    # weight
w <- sort(w, decreasing = T)
w

```

```{r}
svmfit2 = svm(remission ~ lungcapacity + Age, data = train, kernel ="linear", cost = 10, scale = FALSE )
head(train)
summary(svmfit2)
dat = data.frame(lungcapacity = train$lungcapacity, Age = train$Age,  remission = as.factor( train$remission ))
dat
# limites de decis?o:
plot(svmfit2, dat, grid = 100, svSymbol = "X", dataSymbol = 19)
```

O SVM apresentou resultados satisfatórios, porém, foram utilizadas apenas a variáveis contínuas. Dessa forma, vamos avaliar o desfecho remissão com Árvore de Decisão:

```{r}
set.seed(205650)
indexes <- createDataPartition(data$remission, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

model_fit <- rpart(remission ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(train$remission), positive = "1")
ctable_test <- confusionMatrix(predicted_test, as.factor(test$remission), positive = "1")
ctable_train$table
ctable_test$table
ctable_train
ctable_test

fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"), tweak = 1)
dev.off()

```

Observamos uma acurácia de 91% no treino e 100% no teste. São resultados muito satisfatórios, porém é importante ressaltar que o banco possui 91 observações, ou seja, apenas 12 observações foram utilizadas para o teste.

# Avaliação da identificação se o paciente é fumante

Regressao logistica ordinal
```{r}
head(data)
ggplot(data, aes(x = SmokingHx, y = lungcapacity, fill = SmokingHx)) +   geom_boxplot(size = .75) +   facet_grid(Sex ~ DID, margins = FALSE) +   theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

```{r}
head(data)
ggplot(data, aes(x = SmokingHx, y = tumorsize, fill = SmokingHx)) +   geom_boxplot(size = .75) +   facet_grid(Sex ~ DID, margins = FALSE) +   theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

```{r}
head(data)
str(data)
set.seed(205650)
indexes <- createDataPartition(data$SmokingHx, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]

ord_reg <- polr(SmokingHx~tumorsize+pain+mobility+ntumors+Married+Sex+DID+IL6+co2+lungcapacity+nmorphine, data = train, Hess = TRUE)
summary(ord_reg)

summary_table <- coef(summary(ord_reg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

vars com p-value < 0.05: tumorsize, lungcapacity

```{r}
ord_reg_sg <- polr(SmokingHx~tumorsize+lungcapacity, data = train, Hess = TRUE)
summary(ord_reg_sg)
summary_table <- coef(summary(ord_reg_sg))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```
Comparando:
```{r}
predsig<- predict(ord_reg_sg, newdata = train)
pred <- predict(ord_reg, newdata = train)
confusionMatrix(table(predsig, train$SmokingHx))
confusionMatrix(table(pred, train$SmokingHx))
```

```{r}
predtest <- predict(ord_reg, newdata = test)
confusionMatrix(table(predtest, test$SmokingHx))
```


Árvore:

```{r}
set.seed(205650)
indexes <- createDataPartition(data$SmokingHx, p = 0.85, list = FALSE)
train = data[indexes, ]
test = data[-indexes, ]
model_fit <- rpart(SmokingHx ~ ., data = train, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = train, "class")
predicted_test <- predict(model_fit, newdata = test, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(train$SmokingHx))
ctable_test <- confusionMatrix(predicted_test, as.factor(test$SmokingHx))
ctable_train$table
ctable_test$table
ctable_train
ctable_test

fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds", "Greens"), tweak = 1)
dev.off()

```



## Remissao + vars definidas
Utilize um modelo apropriado para analisar a relação entre o desfecho remissão e as variáveis sexo,
histórico familiar, estado civil e DID.

tarefa 3 - Reg logistica
tarefa 4 - tree

```{r}
model_fit <- rpart(remission~Sex+FamilyHx+Married+DID, data = data, method = "class", control = list(minsplit = 20))
predicted_train <- predict(model_fit, newdata = data, "class")
predicted_test <- predict(model_fit, newdata = data, "class")
summary(model_fit)
# importancia das vars
model_fit$variable.importance
#vars que foram usadas na arvore
printcp(model_fit)

#Matriz de confusao
ctable_train <- confusionMatrix(predicted_train, as.factor(data$remission))
ctable_test <- confusionMatrix(predicted_test, as.factor(data$remission))
ctable_train$table
ctable_test$table
ctable_train
ctable_test

#install.packages('rattle')
library(rattle)
library(RColorBrewer)
png('arvore_cannabis.png')
fancyRpartPlot(model_fit, yesno = 2, caption = NULL, palettes=c("Blues", "Reds"), tweak = 1)
dev.off()

```



https://towardsdatascience.com/do-you-know-how-to-choose-the-right-machine-learning-algorithm-among-7-different-types-295d0b0c7f60

https://medium.com/datadriveninvestor/choosing-the-best-algorithm-for-your-classification-model-7c632c78f38f

http://jmlr.csail.mit.edu/papers/v3/guyon03a.html

https://towardsdatascience.com/implementing-and-interpreting-ordinal-logistic-regression-1ee699274cf5

https://www.datacamp.com/community/tutorials/neural-network-models-r

https://www.theanalysisfactor.com/logistic-regression-models-for-multinomial-and-ordinal-variables/

